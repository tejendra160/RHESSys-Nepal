{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e3d52-9c61-4fa7-b509-eae08aa5debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, numpy as np, re, pandas as pd\n",
    "from SALib.sample import morris\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "BASE_DIR = \"/scratch/hjh7hp/Watershed_22_2025_fall/Watershed22_with_new_summer/Sharadha_khola_watershed/1976_SA_1/salyan/model\"\n",
    "SOURCE_DEFS_DIR = os.path.join(BASE_DIR, \"defs\")\n",
    "SA_DEFS_PARENT = os.path.join(BASE_DIR, \"SA_defs_morris\")\n",
    "os.makedirs(SA_DEFS_PARENT, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 2025\n",
    "NUM_TRAJECTORIES = 30\n",
    "NUM_LEVELS = 10\n",
    "\n",
    "unchanged_files = set([\n",
    "    \"basin_basin.def\", \"hill_setting1.def\", \"landuse_setting5.def\",\n",
    "    \"stratum_crop.def\", \"stratum_grass.def\", \"stratum_shrub.def\"\n",
    "])\n",
    "\n",
    "# Add 'zone_setting2010.def' to files_to_change\n",
    "files_to_change = [f for f in os.listdir(SOURCE_DEFS_DIR)\n",
    "                   if f.endswith(\".def\") and f not in unchanged_files]\n",
    "\n",
    "#if 'zone_setting2010.def' not in files_to_change:\n",
    "    #files_to_change.append('zone_setting2010.def')  # Ensure it's included\n",
    "\n",
    "SUM_ONE_GROUPS = {\n",
    "    \"soil_loam_9.def\": [('clay', 'sand', 'silt')],\n",
    "    \"soil_sand_10.def\": [('clay', 'sand', 'silt')],\n",
    "    \"soil_sandy_loam_12.def\": [('clay', 'sand', 'silt')],\n",
    "    \"soil_silt_loam_8.def\": [('clay', 'sand', 'silt')],\n",
    "    \"soil_silty_clay_loam_3.def\": [('clay', 'sand', 'silt')],\n",
    "    \"stratum_cwt_rhododendron_bgc.def\": [\n",
    "        ('epc.leaflitr_fcel','epc.leaflitr_flab','epc.leaflitr_flig'),\n",
    "        ('epc.frootlitr_fcel','epc.frootlitr_flab','epc.frootlitr_flig'),\n",
    "        ('epc.deadwood_fcel','epc.deadwood_flig')],\n",
    "    \"stratum_deciduous.def\": [\n",
    "        ('epc.leaflitr_fcel','epc.leaflitr_flab','epc.leaflitr_flig'),\n",
    "        ('epc.frootlitr_fcel','epc.frootlitr_flab','epc.frootlitr_flig'),\n",
    "        ('epc.deadwood_fcel','epc.deadwood_flig')],\n",
    "    \"stratum_eastern_white_pine.def\": [\n",
    "        ('epc.leaflitr_fcel','epc.leaflitr_flab','epc.leaflitr_flig'),\n",
    "        ('epc.frootlitr_fcel','epc.frootlitr_flab','epc.frootlitr_flig'),\n",
    "        ('epc.deadwood_fcel','epc.deadwood_flig')],\n",
    "    \"stratum_evergreen.def\": [\n",
    "        ('epc.leaflitr_fcel','epc.leaflitr_flab','epc.leaflitr_flig'),\n",
    "        ('epc.frootlitr_fcel','epc.frootlitr_flab','epc.frootlitr_flig'),\n",
    "        ('epc.deadwood_fcel','epc.deadwood_flig')],\n",
    "    \"stratum_localdeciduous.def\": [\n",
    "        ('epc.leaflitr_fcel','epc.leaflitr_flab','epc.leaflitr_flig'),\n",
    "        ('epc.frootlitr_fcel','epc.frootlitr_flab','epc.frootlitr_flig'),\n",
    "        ('epc.deadwood_fcel','epc.deadwood_flig')]\n",
    "}\n",
    "\n",
    "DAY_INT_PARAMS = {\"epc.day_leafoff\", \"epc.day_leafon\", \"epc.ndays_expand\", \"epc.ndays_litfall\"}\n",
    "\n",
    "MULT1000_PARAMS = {\n",
    "    \"epc.vpd_close (x1000)\",\n",
    "    \"epc.vpd_open (x1000)\",\n",
    "    \"gsurf_intercept\",\n",
    "    \"snow_light_ext_coef\"\n",
    "}\n",
    "\n",
    "CN_RANGES = {\"broadleaf\": (20, 50, 45, 98),\n",
    "             \"pine\": (20, 50, 45, 98),\n",
    "             \"alder\": (20, 50, 45, 98),\n",
    "             \"grass\": (20, 50, 45, 98)}\n",
    "\n",
    "\n",
    "def detect_veg_type(fn):\n",
    "    fn = fn.lower()\n",
    "    if \"pine\" in fn or \"evergreen\" in fn: return \"pine\"\n",
    "    elif \"alder\" in fn: return \"alder\"\n",
    "    elif \"grass\" in fn: return \"grass\"\n",
    "    return \"broadleaf\"\n",
    "\n",
    "def enforce_sum_to_one(params, file_prefix):\n",
    "    for grp in SUM_ONE_GROUPS.get(file_prefix + \".def\", []):\n",
    "        keys = [f\"{file_prefix}_{p}\" for p in grp]\n",
    "        vals = [max(params.get(k, 0), 0) for k in keys]\n",
    "        s = sum(vals)\n",
    "        if s == 0:\n",
    "            vals = [1.0 / len(grp)] * len(grp)\n",
    "        else:\n",
    "            vals = [v / s for v in vals]\n",
    "        decimals = 8\n",
    "        vals = [round(v, decimals) for v in vals[:-1]]\n",
    "        last_val = round(1.0 - sum(vals), decimals)\n",
    "        vals.append(last_val)\n",
    "        total = sum(vals)\n",
    "        if abs(total-1.0) > 1e-8:\n",
    "            vals = [round(v + (1.0-total)/len(vals), decimals) for v in vals]\n",
    "        for k, v in zip(keys, vals):\n",
    "            params[k] = v\n",
    "    return params\n",
    "\n",
    "def enforce_cn(params, file_prefix):\n",
    "    veg = detect_veg_type(file_prefix)\n",
    "    leaf_min, leaf_max, lit_min, lit_max = CN_RANGES[veg]\n",
    "    leaf_cn_key = f\"{file_prefix}_epc.leaf_cn\"\n",
    "    leaflitr_cn_key = f\"{file_prefix}_epc.leaflitr_cn\"\n",
    "    if leaf_cn_key in params:\n",
    "        params[leaf_cn_key] = np.clip(params[leaf_cn_key], leaf_min, leaf_max)\n",
    "    if leaflitr_cn_key in params:\n",
    "        min_lit = max(lit_min, params.get(leaf_cn_key, leaf_min)+5)\n",
    "        params[leaflitr_cn_key] = np.clip(params[leaflitr_cn_key], min_lit, lit_max)\n",
    "    return params\n",
    "\n",
    "def enforce_days(params, file_prefix):\n",
    "    for d in DAY_INT_PARAMS:\n",
    "        key = f\"{file_prefix}_{d}\"\n",
    "        if key in params:\n",
    "            params[key] = int(round(min(365,max(0,params[key]))))\n",
    "    l_on = f\"{file_prefix}_epc.day_leafon\"\n",
    "    l_off = f\"{file_prefix}_epc.day_leafoff\"\n",
    "    if l_on in params and l_off in params:\n",
    "        if params[l_on] >= params[l_off]:\n",
    "            params[l_on] = min(params[l_on], 180)\n",
    "            params[l_off] = max(params[l_on]+30, params[l_off])\n",
    "            params[l_off] = min(365, params[l_off])\n",
    "    return params\n",
    "\n",
    "def enforce_multiple_1000(params):\n",
    "    for k in params:\n",
    "        for pname in MULT1000_PARAMS:\n",
    "            if k.endswith(\"_\" + pname) or k == pname:\n",
    "                params[k] = int(np.floor(params[k] / 1000)*1000)\n",
    "    return params\n",
    "\n",
    "def enforce_all_constraints(params):\n",
    "    for f in files_to_change:\n",
    "        file_prefix = f.replace('.def','')\n",
    "        params = enforce_sum_to_one(params, file_prefix)\n",
    "        params = enforce_cn(params, file_prefix)\n",
    "        params = enforce_days(params, file_prefix)\n",
    "    params = enforce_multiple_1000(params)\n",
    "    return params\n",
    "\n",
    "\n",
    "def parse_param_line(line):\n",
    "    # Update regex so it matches zone parameters too (including '(= lapse rate)' suffix)\n",
    "    m = re.match(r'^\\s*([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)[ \\t]+([a-zA-Z0-9_\\.]+(?: \\(= lapse rate\\))?)', line)\n",
    "    return (float(m.group(1)), m.group(2), line[m.end():]) if m else (None, None, None)\n",
    "\n",
    "def is_integer_param(file_prefix, param_name):\n",
    "    # If any zone parameters are integers, handle here (most appear to be float)\n",
    "    # Add additional logic if zone parameters should be integer-typed\n",
    "    if param_name in DAY_INT_PARAMS:\n",
    "        return True\n",
    "    if param_name in MULT1000_PARAMS:\n",
    "        return True\n",
    "    # No additional integer params for the zone parameters needed\n",
    "    full_key = f\"{file_prefix}_{param_name}\"\n",
    "    return any([full_key.endswith(\"_\" + p) for p in DAY_INT_PARAMS | MULT1000_PARAMS])\n",
    "\n",
    "bounds = pd.read_csv(os.path.join(BASE_DIR, \"Parameters_range_values_Final_with_zone.csv\"))\n",
    "param_names, bnds = [], []\n",
    "for _, r in bounds.iterrows():\n",
    "    try:\n",
    "        lo, hi = float(r['lower limit']), float(r['upper limit'])\n",
    "        if lo < hi:\n",
    "            param_names.append(r['Parameter name'])\n",
    "            bnds.append([lo, hi])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "problem = {'num_vars': len(param_names), 'names': param_names, 'bounds': bnds}\n",
    "X = morris.sample(problem, N=NUM_TRAJECTORIES, num_levels=NUM_LEVELS, seed=RANDOM_SEED)\n",
    "raw_df = pd.DataFrame(X, columns=param_names)\n",
    "\n",
    "adjusted_samples = []\n",
    "for idx, row in raw_df.iterrows():\n",
    "    params = row.to_dict()\n",
    "    params = enforce_all_constraints(params)\n",
    "    for k, v in params.items():\n",
    "        if \"_\" in k:\n",
    "            prefix, param = k.rsplit(\"_\", 1)\n",
    "            if is_integer_param(prefix, param):\n",
    "                if param in MULT1000_PARAMS:\n",
    "                    params[k] = int(np.floor(v / 1000)*1000)\n",
    "                else:\n",
    "                    params[k] = int(round(v))\n",
    "            elif isinstance(v, float):\n",
    "                params[k] = round(v, 8)\n",
    "        elif isinstance(v, float):\n",
    "            params[k] = round(v, 8)\n",
    "    adjusted_samples.append(params)\n",
    "\n",
    "adjusted_df = pd.DataFrame(adjusted_samples, columns=param_names)\n",
    "adjusted_df.insert(0, \"defs_set\", [f\"defs{i+1}\" for i in range(len(adjusted_df))])\n",
    "adjusted_df.to_csv(os.path.join(BASE_DIR, \"defs_parameter_mapping.csv\"), index=False)\n",
    "adjusted_df.drop(\"defs_set\", axis=1).to_csv(os.path.join(BASE_DIR, \"morris_parameter_set_full.csv\"), index=False)\n",
    "\n",
    "def write_defs(sample_params, idx):\n",
    "    defsdir = os.path.join(SA_DEFS_PARENT, f\"defs{idx}\")\n",
    "    os.makedirs(defsdir, exist_ok=True)\n",
    "    for f in unchanged_files:\n",
    "        shutil.copy2(os.path.join(SOURCE_DEFS_DIR, f), os.path.join(defsdir, f))\n",
    "    for f in files_to_change:\n",
    "        file_prefix = f.replace('.def','')\n",
    "        lines = open(os.path.join(SOURCE_DEFS_DIR, f)).read().splitlines(True)\n",
    "        out = []\n",
    "        for ln in lines:\n",
    "            val, p, rest = parse_param_line(ln)\n",
    "            if not p:\n",
    "                out.append(ln)\n",
    "                continue\n",
    "            if p.endswith(\"default_ID\"):\n",
    "                out.append(ln)\n",
    "                continue\n",
    "            k = f\"{file_prefix}_{p}\"\n",
    "            if k in sample_params:\n",
    "                nv = sample_params[k]\n",
    "                if is_integer_param(file_prefix, p):\n",
    "                    if p in MULT1000_PARAMS:\n",
    "                        nv = int(np.floor(nv / 1000) * 1000)\n",
    "                    out.append(f\"{int(nv)} {p}{rest}\")\n",
    "                elif isinstance(nv, float) and float(nv).is_integer():\n",
    "                    out.append(f\"{int(nv)} {p}{rest}\")\n",
    "                else:\n",
    "                    out.append(f\"{nv:.8f} {p}{rest}\")\n",
    "            else:\n",
    "                out.append(ln)\n",
    "        open(os.path.join(defsdir, f), 'w').writelines(out)\n",
    "    return defsdir\n",
    "\n",
    "maprec = []\n",
    "for i, row in adjusted_df.iterrows():\n",
    "    defsdir = write_defs(row.to_dict(), i + 1)\n",
    "    maprec.append(row.to_dict())\n",
    "    maprec[-1]['defs_set'] = f\"defs{i+1}\"\n",
    "    print(\"Created:\", defsdir)\n",
    "\n",
    "NUM_DEFS_FOLDERS = len(adjusted_df)\n",
    "\n",
    "pd.DataFrame(maprec).to_csv(os.path.join(BASE_DIR, \"defs_parameter_mapping.csv\"), index=False)\n",
    "print(\"Mapping file written.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
